	var wg sync.WaitGroup
	wg.Add(partitions + 1)

	nextPartition := uint32(0)

	go func() {
		wg.Done()
	}()

	thr := runtime.NumCPU()
	for i := 0; i < thr; i++ {
		go func() {
			for {
				p := int(atomic.AddUint32(&nextPartition, 1))-1
				if p >= partitions {
					break
				}
				b,e := partitionRange(p)
				for ;b!=e; b++ {

				}
			}
			wg.Done()
		}()
	}

	wg.Wait()


    type Pyramid struct {
	Len     int
	MinZoom int
	MaxZoom int
	h       []*hilbert.Hilbert // one fore each zoom
	start   []int
}

func (p *Pyramid) Xyz(id int) (x, y, z int, e error) {
	for z, h := range p.h {
		sz := h.N * h.N
		if id >= sz {
			id -= sz
		} else {
			x, y, _ = h.Map(id)
			return x, y, z + p.MinZoom, nil
		}
	}
	return 0, 0, 0, fmt.Errorf("out of bounds")
}
func (p *Pyramid) FromXyz(x, y, z int) (id int, e error) {
	

	return 0, fmt.Errorf("out of bounds")
}

func NewPyramid(minZoom, maxZoom int) *Pyramid {
	o := &Pyramid{
		MinZoom: minZoom,
		MaxZoom: maxZoom,
		h:       []*hilbert.Hilbert{},
	}
	o.h = make([]*hilbert.Hilbert, o.MaxZoom-o.MinZoom)
	o.start = make([]int, 1 + o.MaxZoom-o.MinZoom)
	cnt := 0
	for x := range o.h {
		o.h[x], _ = hilbert.NewHilbert(1 << (x + o.MinZoom))
		cnt += o.h[x].N * o.h[x].N
		o.start[x+1] = cnt

	}
	o.Len = cnt
	// for z := o.MinZoom; z < o.MaxZoom; z++ {
	// 	o.Len += (1 << z) * (1 << z)
	// }
	return o
}
	rs, e := db.Query("select tile_id,count(*) from shallow_tiles group by 1 having count(*)>1 order by 2")
	if e != nil {
		return e
	}
	var tile_id uint32
	symbol_table := map[uint32]uint32{}
	count := uint32(0)
	for rs.Next() {
		rs.Scan(&tile_id)
		symbol_table[tile_id] = count
		count++
	}
	rs.Close()



// the main value of having partitions is allowing the smallest reasonable files
// we could write them sequentially, should we?
// the first partition will always be reused tiles in this scheme
func WriteMbtiles(inpath string, outpath string, partitions int, maxfile int) error {
	thr := runtime.NumCPU()

	db, e := sql.Open("sqlite", inpath)
	if e != nil {
		return e
	}
	getTileData, e := db.Prepare("select * from tiles_data where tile_data_id=?")
	if e != nil {
		panic(e)
	}

	// count the tiles? this should just be the pyramid.
	pyr := NewPyramid(0, 15)
	splits := PartitionRange(0, pyr.Len, partitions)
	// how should partitioning interact with the clipping polygon(s)?

	// get the reused tiles and cluster them to make them easier to cache.
	// we might as well read the entire shallow_tiles table and then sort by hilbert
	// we can do our own binning then.

	// how should we change this to allow a range of x,y,14?
	// this is pyramid, tile so we can sort by hilbert but fetch from database by tile.
	// should we map
	shallow := make([]uint64, pyr.Len)
	// this is count, tile. lets us sort by count so we can pack the most reused tiles to make them easy to cache. Count here _should_ be a weight that includes usefullness but future work.
	useCount := make([]uint64, pyr.Len)
	rs, e := db.Query("select  from zoom_level integer, tile_column integer,tile_row integer, tile_data_id integer")
	if e != nil {
		return e
	}
	var zoom_level, tile_column, tile_row, tile_data_id int
	i := 0
	for rs.Next() {
		rs.Scan(&zoom_level, &tile_column, &tile_row, &tile_data_id)
		// generate the hilbert id and
		id, e := pyr.FromXyz(tile_column, tile_row, zoom_level)
		if e != nil {
			panic(e)
		}
		shallow[i] = (uint64(id) << 32) + uint64(tile_data_id)
		useCount[tile_data_id]++
	}
	// sort the useCount by the count we should do this loop with pargo
	for j := 0; j < i; i++ {
		useCount[j] = (useCount[j] << 32) + uint64(j)
	}
	sorty.SortSlice(useCount)

	// now we can map the reused tiles
	tile_cache := map[uint32]uint32{}

	var repeated int
	for i, v := range useCount {
		count, tile_data_id := unpair(v)
		if count < 2 {
			repeated = i
			break
		}
		tile_cache[uint32(tile_data_id)] = uint32(i)
	}

	// our final data will have reuse partition. how should we reference it?

	var wg sync.WaitGroup
	wg.Add(partitions + 1)
	nextPartition := uint32(0)

	// write the reused partition
	go func() {
		var tile_data []byte
		log.Printf("Writing reused %d", repeated)
		for i := 0; i < 10; i++ {
			log.Printf("")
		}
		wr := OpenSplitLog(fmt.Sprintf("%s_", outpath), maxfile)
		for i := 0; i < repeated; i++ {
			_, tile_data_id := unpair(useCount[i])
			getTileData.QueryRow(tile_data_id).Scan(&tile_data)
			wr.Write(tile_data)
		}

		wg.Done()
	}()

	for i := 0; i < thr; i++ {
		go func() {
			var tile_data []byte
			for {
				p := int(atomic.AddUint32(&nextPartition, 1)) - 1
				if p >= partitions {
					break
				}
				b := splits[p]
				e := splits[p+1]
				log.Printf("Writing %d,%d to %d", b, e, p)
				// write the entire partition
				if !dry_run {
					wr := OpenSplitLog(fmt.Sprintf("%s_%d", outpath, p), maxfile)
					for ; b != e; b++ {
						_, tile_data_id := unpair(shallow[b])
						loc, ok := tile_cache[tile_data_id]
						if ok {
							_ = loc
						} else {
							getTileData.QueryRow(tile_data_id).Scan(&tile_data)
							wr.Write(tile_data)
						}
					}
				}
			}
			wg.Done()
		}()
	}

	wg.Wait()
	return nil

}

/*
type MbtileSet struct {
	p         Pyramid
	db        *sql.DB
	getTileId *sql.Stmt
	getTile   *sql.Stmt

	// maps a pyramid index to a value in the Repeats dictionary.
	repeated         map[int]int
	repeated_tile_id []int
}

var _ BlobArray = (*MbtileSet)(nil)

func (b *MbtileSet) Len() int {
	return b.p.Len
}

const s1 = "select tile_id,count(*) from shallow_tiles group by 1 having count(*)>1 order by 1"

func NewMbtileSet(path string) (*MbtileSet, error) {
	// open sqlite and find the repeated tile ids.
	db, e := sql.Open("sqlite", path)
	if e != nil {
		return nil, e
	}
	s1, e := db.Prepare(s1)
	if e != nil {
		return nil, e
	}
	s2, e := db.Prepare(" ")
	if e != nil {
		return nil, e
	}
	// find the repeats an intialize those directories.

	return &MbtileSet{
		p:         Pyramid{},
		db:        db,
		getTileId: s1,
		getTile:   s2,
	}, nil
}

// start with the most used tiles

// getChunks implements Bucketable
// repeats at beginning.
func (m *MbtileSet) Read(start int, end int) ([][]byte, []int, error) {
	var b []byte
	r := make([][]byte, 0, end-start)
	rs := []int{}

	for ; start < len(m.repeated_tile_id); start++ {
		m.getTile.QueryRow(m.repeated_tile_id[start]).Scan(&b)
		// we might need to copy the block? does scan overwrite?
		r = r.append(b)
	}

	start -= len(m.Repeats)
	for ; start != end; start++ {
		x, y, z, err := m.p.Xyz(start)
		if err != nil {
			return nil, nil, err
		}
		var tileid int
		err = m.getTileId.QueryRow(x, y, z).Scan(&tileid)
		if err != nil {
			return nil, nil, err
		}

		sym, ok := m.repeated[tileid]
		if !ok {
			m.getTile.QueryRow(tileid).Scan(&b)
			r = append(r, b)
			rs = append(rs, 0)
		} else {
			rs = append(rs, sym)
		}
	}
	return r, rs, nil
}
*/
